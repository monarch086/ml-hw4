{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e39e67b-e6db-43de-a498-25bf07e301d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\kyrylo_polinchuk\\python\\kyrylo\\venv\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\kyrylo_polinchuk\\python\\kyrylo\\venv\\lib\\site-packages (from nltk) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\kyrylo_polinchuk\\python\\kyrylo\\venv\\lib\\site-packages (from nltk) (4.66.1)\n",
      "Requirement already satisfied: click in c:\\users\\kyrylo_polinchuk\\python\\kyrylo\\venv\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\kyrylo_polinchuk\\python\\kyrylo\\venv\\lib\\site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\kyrylo_polinchuk\\python\\kyrylo\\venv\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.1.2; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\Kyrylo_Polinchuk\\Python\\Kyrylo\\venv\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import os\n",
    "import time\n",
    "import re\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b10f5ce5-19c0-409d-ad07-f851ee20ba84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in the train dataset: 159571\n",
      "Number of samples in the test dataset: 63978\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')\n",
    "train_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')\n",
    "num_samples_train = train_data.shape[0]\n",
    "num_samples_test = test_data.shape[0]\n",
    "print(\"Number of samples in the train dataset:\", num_samples_train)\n",
    "print(\"Number of samples in the test dataset:\", num_samples_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3771e234-af99-4be4-9f40-7a280db88d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         Explanation\\nWhy the edits made under my usern...\n",
      "1         D'aww! He matches this background colour I'm s...\n",
      "2         Hey man, I'm really not trying to edit war. It...\n",
      "3         \"\\nMore\\nI can't make any real suggestions on ...\n",
      "4         You, sir, are my hero. Any chance you remember...\n",
      "                                ...                        \n",
      "159566    \":::::And for the second time of asking, when ...\n",
      "159567    You should be ashamed of yourself \\n\\nThat is ...\n",
      "159568    Spitzer \\n\\nUmm, theres no actual article for ...\n",
      "159569    And it looks like it was actually you who put ...\n",
      "159570    \"\\nAnd ... I really don't think you understand...\n",
      "Name: comment_text, Length: 159571, dtype: object\n",
      "0         the made under my fan were werent just closure...\n",
      "1         this background colour seemingly stuck with ta...\n",
      "2         man really not trying to edit war just that th...\n",
      "3         i cant make any real on improvement i if the s...\n",
      "4         sir are my hero chance you remember what page ...\n",
      "                                ...                        \n",
      "159566    for the second time of when your view complete...\n",
      "159567    should be ashamed of yourself is a horrible th...\n",
      "159568       theres no actual article for prostitution ring\n",
      "159569    it like it was actually you who put on the spe...\n",
      "159570    i really dont think you understand i came here...\n",
      "Name: cleaned_text, Length: 159571, dtype: object\n"
     ]
    }
   ],
   "source": [
    "nltk_words = set(words.words())\n",
    "\n",
    "def clean_text(sample):\n",
    "    sample = re.sub(f\"[{string.punctuation}]\", '', sample)\n",
    "    sample = re.sub(r'http\\S+', '', sample)\n",
    "    sample = re.sub(r'[^a-zA-Z0-9]', ' ', sample)\n",
    "    sample_words = sample.split()\n",
    "    sample_words = [word.lower() for word in sample_words if word in nltk_words]\n",
    "    sample = ' '.join(sample_words)\n",
    "    return sample\n",
    "train_data['cleaned_text'] = train_data['comment_text'].apply(clean_text)\n",
    "print(train_data['comment_text'])\n",
    "print(train_data['cleaned_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee847d4f-4f0c-4ca4-8158-9037ba47c519",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['cleaned_text'] = test_data['comment_text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42ec9479-8b23-4902-ac4d-55c46b2a0ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(text):\n",
    "    words = text.split()\n",
    "    processed_words = []\n",
    "    for word in words:\n",
    "        try:\n",
    "            processed_word = num2words.num2words(word) if word.isnumeric() else word\n",
    "            processed_words.append(processed_word)\n",
    "        except Exception as e:\n",
    "            processed_words.append(word)\n",
    "    tokens = word_tokenize(' '.join(processed_words))\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58b7afa5-5fa1-40b6-84a4-11787c612057",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['processed_text'] = train_data['cleaned_text'].apply(process_text)\n",
    "test_data['processed_text'] = test_data['cleaned_text'].apply(process_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f9792e7-0fff-4eb1-8a63-d44f24eb1ebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         Explanation\\nWhy the edits made under my usern...\n",
      "1         D'aww! He matches this background colour I'm s...\n",
      "2         Hey man, I'm really not trying to edit war. It...\n",
      "3         \"\\nMore\\nI can't make any real suggestions on ...\n",
      "4         You, sir, are my hero. Any chance you remember...\n",
      "                                ...                        \n",
      "159566    \":::::And for the second time of asking, when ...\n",
      "159567    You should be ashamed of yourself \\n\\nThat is ...\n",
      "159568    Spitzer \\n\\nUmm, theres no actual article for ...\n",
      "159569    And it looks like it was actually you who put ...\n",
      "159570    \"\\nAnd ... I really don't think you understand...\n",
      "Name: comment_text, Length: 159571, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(train_data['comment_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33053f46-de1c-4305-9630-5e6501fa4171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         the made under my fan were werent just closure...\n",
      "1         this background colour seemingly stuck with ta...\n",
      "2         man really not trying to edit war just that th...\n",
      "3         i cant make any real on improvement i if the s...\n",
      "4         sir are my hero chance you remember what page ...\n",
      "                                ...                        \n",
      "159566    for the second time of when your view complete...\n",
      "159567    should be ashamed of yourself is a horrible th...\n",
      "159568       theres no actual article for prostitution ring\n",
      "159569    it like it was actually you who put on the spe...\n",
      "159570    i really dont think you understand i came here...\n",
      "Name: processed_text, Length: 159571, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(train_data['processed_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d26a4eb1-5cfd-4ef2-8c4d-45b6c9815281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        Thank you for understanding. I think very high...\n",
      "1                         :Dear god this site is horrible.\n",
      "2        \"::: Somebody will invariably try to add Relig...\n",
      "3        \" \\n\\n It says it right there that it IS a typ...\n",
      "4        \" \\n\\n == Before adding a new product to the l...\n",
      "                               ...                        \n",
      "63973    :Jerome, I see you never got around to thisâ€¦! ...\n",
      "63974    ==Lucky bastard== \\n http://wikimediafoundatio...\n",
      "63975    ==shame on you all!!!== \\n\\n You want to speak...\n",
      "63976    MEL GIBSON IS A NAZI BITCH WHO MAKES SHITTY MO...\n",
      "63977    \" \\n\\n == Unicorn lair discovery == \\n\\n Suppo...\n",
      "Name: comment_text, Length: 63978, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(test_data['comment_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6d452a6-6362-40b0-a2db-6e0f57063109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        you for understanding i think very highly of y...\n",
      "1                                god this site is horrible\n",
      "2        will invariably try to add mean the way people...\n",
      "3        it right there that it a type the of instituti...\n",
      "4        a new product to the list make sure its releva...\n",
      "                               ...                        \n",
      "63973    jerome i see you never got around to this i m ...\n",
      "63974               bastard you are famous now i envy that\n",
      "63975    shame on you all want to speak about and not a...\n",
      "63976                                                  a a\n",
      "63977    lair discovery a unicorn lair been discovered ...\n",
      "Name: processed_text, Length: 63978, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(test_data['processed_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8962d3db-8615-43ec-b42a-67af23894457",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.drop(columns=['comment_text', 'cleaned_text'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba35b80a-02c8-481d-adeb-0251b4e3b827",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.drop(columns=['comment_text', 'cleaned_text'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba5fc32c-d90f-46f7-a7ae-ddfa73017718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Unnamed: 0                id  \\\n",
      "0               5  0001ea8717f6de06   \n",
      "1               7  000247e83dcc1211   \n",
      "2              11  0002f87b16116a7f   \n",
      "3              13  0003e1cccfd5a40a   \n",
      "4              14  00059ace3e3e9a53   \n",
      "...           ...               ...   \n",
      "63973      153150  fff8f64043129fa2   \n",
      "63974      153151  fff9d70fe0722906   \n",
      "63975      153154  fffa8a11c4378854   \n",
      "63976      153155  fffac2a094c8e0e2   \n",
      "63977      153156  fffb5451268fb5ba   \n",
      "\n",
      "                                          processed_text  \n",
      "0      you for understanding i think very highly of y...  \n",
      "1                              god this site is horrible  \n",
      "2      will invariably try to add mean the way people...  \n",
      "3      it right there that it a type the of instituti...  \n",
      "4      a new product to the list make sure its releva...  \n",
      "...                                                  ...  \n",
      "63973  jerome i see you never got around to this i m ...  \n",
      "63974             bastard you are famous now i envy that  \n",
      "63975  shame on you all want to speak about and not a...  \n",
      "63976                                                a a  \n",
      "63977  lair discovery a unicorn lair been discovered ...  \n",
      "\n",
      "[63978 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "409f6dd3-93b2-40b2-af4f-8db4d4b06de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path = 'train_processed.csv'\n",
    "\n",
    "if os.path.exists(csv_file_path):\n",
    "    os.remove(csv_file_path)\n",
    "train_data.to_csv(csv_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dd4ad8cf-cc50-49ba-9977-883c74f3bdd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path = 'test_processed.csv'\n",
    "\n",
    "if os.path.exists(csv_file_path):\n",
    "    os.remove(csv_file_path)\n",
    "test_data.to_csv(csv_file_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
